{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a69df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from time import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22a238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(tf.keras.layers.Layer):\n",
    "    # 设置模块的构成\n",
    "    def __init__(self, c1, c2, c3, c4):\n",
    "        super().__init__()\n",
    "        # 线路1:1*1 RELU same c1\n",
    "        self.p1_1 = tf.keras.layers.Conv2D(\n",
    "            c1, kernel_size=1, activation=\"relu\", padding=\"same\")\n",
    "        # 线路2:1*1 RELU same c2[0]\n",
    "        self.p2_1 = tf.keras.layers.Conv2D(\n",
    "            c2[0], kernel_size=1, activation=\"relu\", padding=\"same\")\n",
    "        # 线路2:3*3 RELU same c2[1]\n",
    "        self.p2_2 = tf.keras.layers.Conv2D(\n",
    "            c2[1], kernel_size=3, activation=\"relu\", padding='same')\n",
    "        # 线路3:1*1 RELU same c3[0]\n",
    "        self.p3_1 = tf.keras.layers.Conv2D(\n",
    "            c3[0], kernel_size=1, activation=\"relu\", padding=\"same\")\n",
    "        # 线路3:5*5 RELU same c3[1]\n",
    "        self.p3_2 = tf.keras.layers.Conv2D(\n",
    "            c3[1], kernel_size=5, activation=\"relu\", padding='same')\n",
    "        # 线路4: max-pool\n",
    "        self.p4_1 = tf.keras.layers.MaxPool2D(\n",
    "            pool_size=3, padding=\"same\", strides=1)\n",
    "        # 线路4:1*1\n",
    "        self.p4_2 = tf.keras.layers.Conv2D(\n",
    "            c4, kernel_size=1, activation=\"relu\", padding=\"same\")\n",
    "\n",
    "    # 前行传播过程\n",
    "    def call(self, x):\n",
    "        # 线路1\n",
    "        p1 = self.p1_1(x)\n",
    "        # 线路2\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        # 线路3\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        # 线路4\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # concat\n",
    "        outputs = tf.concat([p1, p2, p3, p4], axis=-1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6f0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集加载函数，指明数据集的位置并统一处理为imgheight*imgwidth的大小，同时设置batch\n",
    "def load_data(dir_path):\n",
    "    fopen = open(dir_path, 'r')\n",
    "    lines = fopen.read().splitlines()   # 逐行读取txt\n",
    "    count = len(open(dir_path, 'r').readlines())      # 计算txt有多少行\n",
    " \n",
    "    data_set = np.empty((count, 27, 1024, 4), dtype=\"float32\")\n",
    "    label = np.zeros((count), dtype=\"uint8\")\n",
    " \n",
    "    i = 0\n",
    "    for line in lines:\n",
    " \n",
    "        line = line.split(\" \")          # 利用空格进行分割\n",
    " \n",
    "        # img = Image.open(line[0])\n",
    "        sample = np.load(line[0])\n",
    "        # print(i, sample.size)\n",
    "        # img = skimage.io.image(line[0])\n",
    "        label[i] = int(line[1])\n",
    " \n",
    "        # img = img.convert('L')          # 转灰度图像\n",
    "        array = np.asarray(sample, dtype=\"float32\")\n",
    "        data_set[i, :, :, :] = array\n",
    " \n",
    "        i += 1\n",
    " \n",
    "    return data_set, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58d32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建mobilenet模型\n",
    "# 模型加载，指定图片处理的大小和是否进行迁移学习\n",
    "def model_load(IMG_SHAPE=(27, 1024, 4), class_num=10):\n",
    "    # 微调的过程中不需要进行归一化的处理\n",
    "    # 加载预训练的mobilenet模型\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "    # 将模型的主干参数进行冻结\n",
    "    base_model.trainable = False\n",
    "\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # 进行归一化的处理\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1. / 127.5, offset=-1, input_shape=IMG_SHAPE),\n",
    "        # 设置主干模型\n",
    "        base_model,\n",
    "        # 对主干模型的输出进行全局平均池化\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        # 通过全连接层映射到最后的分类数目上\n",
    "        tf.keras.layers.Dense(class_num, activation='softmax')\n",
    "    ])\n",
    "    model.summary()\n",
    "    # 模型训练的优化器为adam优化器，模型的损失函数为交叉熵损失函数\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca33bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示训练过程的曲线\n",
    "def show_loss_acc(history):\n",
    "    # 从history中提取模型训练集和验证集准确率信息和误差信息\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # 按照上下结构将图画输出\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()), 1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.savefig('results/results_mobilenet.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eede4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    # 开始训练，记录开始时间\n",
    "    begin_time = time()\n",
    "    # todo 加载数据集， 修改为你的数据集的路径\n",
    "#     train_ds, val_ds, class_names = data_load(\"H:/CNN2/new_data/train\",\n",
    "#                                            \"H:/CNN2/new_data/val\", 224, 224, 16)\n",
    "    train_list = './slice_data/train_label.txt'\n",
    "    val_list = './slice_data/val_label.txt'\n",
    "    x_sample, x_label = load_data(train_list)\n",
    "    y_sample, y_label = load_data(val_list)\n",
    "    x_label = tf.squeeze(x_label)\n",
    "    x_label = tf.one_hot(x_label, depth = 10)\n",
    "    y_label = tf.squeeze(y_label)\n",
    "    y_label = tf.one_hot(y_label, depth = 10)\n",
    "    db_train = tf.data.Dataset.from_tensor_slices((x_sample,x_label)).batch(256)\n",
    "    db_val = tf.data.Dataset.from_tensor_slices((y_sample,y_label)).batch(256)\n",
    "#     print(class_names)\n",
    "    # 加载模型\n",
    "    model = model_load()\n",
    "    # 指明训练的轮数epoch，开始训练\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "    # todo 保存模型， 修改为你要保存的模型的名称\n",
    "    model.save(\"models/mobilenet_picture_video_text.h5\")\n",
    "    # 记录结束时间\n",
    "    end_time = time()\n",
    "    run_time = end_time - begin_time\n",
    "    print('该循环程序运行时间：', run_time, \"s\")  # 该循环程序运行时间： 1.4201874732\n",
    "    # 绘制模型训练过程图\n",
    "    show_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea51dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 14:41:51.555035: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; Received `input_shape=(27, 1024, 4)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jg/92gjcs8j4nz44t6fy_zhq2400000gn/T/ipykernel_81741/3061805362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jg/92gjcs8j4nz44t6fy_zhq2400000gn/T/ipykernel_81741/3482599857.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     print(class_names)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 加载模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# 指明训练的轮数epoch，开始训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jg/92gjcs8j4nz44t6fy_zhq2400000gn/T/ipykernel_81741/215372325.py\u001b[0m in \u001b[0;36mmodel_load\u001b[0;34m(IMG_SHAPE, class_num)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# 微调的过程中不需要进行归一化的处理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 加载预训练的mobilenet模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                    \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                    weights='imagenet')\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/applications/mobilenet_v2.py\u001b[0m in \u001b[0;36mMobileNetV2\u001b[0;34m(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mdefault_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m   input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[1;32m    280\u001b[0m       \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    370\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`input_shape` must be a tuple of three integers.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m           raise ValueError('The input must have 3 channels; Received '\n\u001b[0m\u001b[1;32m    373\u001b[0m                            f'`input_shape={input_shape}`')\n\u001b[1;32m    374\u001b[0m         if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; Received `input_shape=(27, 1024, 4)`"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad1c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
